{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Nearest Neighbors and Decision Trees\n",
    "\n",
    "## Lab objectives\n",
    "\n",
    "* Classification with decision trees and random forests.\n",
    "* Cross-validation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "\n",
    "dataset = CIFAR10('./CIFAR10/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Nearest Neighbor\n",
    "\n",
    "The following example uses the Nearest Neighbor algorithm on the Histogram of Gradient decriptors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the **descriptive performance** of this classifier ?\n",
    "* Modify the code to estimate the **predictive performance**.\n",
    "* Use cross-validation to find the best hyper-parameters for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 1.0\n",
      "[[5000    0    0]\n",
      " [   0 5000    0]\n",
      " [   0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.694\n",
      "[[609 258 133]\n",
      " [ 63 754 183]\n",
      " [ 26 255 719]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents hyperparameters sont les suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [1, 2, 3]\n",
    "weights = ['uniform', 'distance']\n",
    "p = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  1\n",
      "Weights  uniform\n",
      "Power  1\n",
      "La moyenne est  0.7456\n",
      "Power  2\n",
      "La moyenne est  0.6878\n",
      "Weights  distance\n",
      "Power  1\n",
      "La moyenne est  0.7456\n",
      "Power  2\n",
      "La moyenne est  0.6878\n",
      "Number of neighbors  2\n",
      "Weights  uniform\n",
      "Power  1\n",
      "La moyenne est  0.7438\n",
      "Power  2\n",
      "La moyenne est  0.6868666666666667\n",
      "Weights  distance\n",
      "Power  1\n",
      "La moyenne est  0.7456\n",
      "Power  2\n",
      "La moyenne est  0.6878\n",
      "Number of neighbors  3\n",
      "Weights  uniform\n",
      "Power  1\n",
      "La moyenne est  0.7695333333333333\n",
      "Power  2\n",
      "La moyenne est  0.7060666666666666\n",
      "Weights  distance\n",
      "Power  1\n",
      "La moyenne est  0.7635333333333333\n",
      "Power  2\n",
      "La moyenne est  0.6988\n"
     ]
    }
   ],
   "source": [
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for w in weights:\n",
    "        print(\"Weights \", w)\n",
    "        for power in p:\n",
    "            print(\"Power \", power)\n",
    "            clf = KNeighborsClassifier(n_neighbors=n, weights=w, p=power)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus le nombre de neighbors est grand, meilleure est l'accuracy. Power = 1 donne systématiquement des meilleurs résultats que power = 2.\n",
    "Pour neighbors = 3, weight = 'distance' était mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  3\n",
      "Weights  uniform\n",
      "Leaf size  20\n",
      "La moyenne est  0.7060666666666666\n",
      "Leaf size  30\n",
      "La moyenne est  0.7060666666666666\n",
      "Leaf size  40\n",
      "La moyenne est  0.7060666666666666\n",
      "Weights  distance\n",
      "Leaf size  20\n",
      "La moyenne est  0.6988\n",
      "Leaf size  30\n",
      "La moyenne est  0.6988\n",
      "Leaf size  40\n",
      "La moyenne est  0.6988\n",
      "Number of neighbors  4\n",
      "Weights  uniform\n",
      "Leaf size  20\n",
      "La moyenne est  0.7002\n",
      "Leaf size  30\n",
      "La moyenne est  0.7002\n",
      "Leaf size  40\n",
      "La moyenne est  0.7002\n",
      "Weights  distance\n",
      "Leaf size  20\n",
      "La moyenne est  0.7051999999999999\n",
      "Leaf size  30\n",
      "La moyenne est  0.7051999999999999\n",
      "Leaf size  40\n",
      "La moyenne est  0.7051999999999999\n",
      "Number of neighbors  5\n",
      "Weights  uniform\n",
      "Leaf size  20\n",
      "La moyenne est  0.7097333333333333\n",
      "Leaf size  30\n",
      "La moyenne est  0.7097333333333333\n",
      "Leaf size  40\n",
      "La moyenne est  0.7097333333333333\n",
      "Weights  distance\n",
      "Leaf size  20\n",
      "La moyenne est  0.7029333333333333\n",
      "Leaf size  30\n",
      "La moyenne est  0.7029333333333333\n",
      "Leaf size  40\n",
      "La moyenne est  0.7029333333333333\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [3, 4, 5]\n",
    "leaf_size = [20, 30, 40]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for w in weights:\n",
    "        print(\"Weights \", w)\n",
    "        for leaf in leaf_size:\n",
    "            print(\"Leaf size \", leaf)\n",
    "            clf = KNeighborsClassifier(n_neighbors=n, weights=w, leaf_size=leaf)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  3\n",
      "Leaf size  30\n",
      "La moyenne est  0.7695333333333333\n",
      "Leaf size  50\n",
      "La moyenne est  0.7695333333333333\n",
      "Number of neighbors  4\n",
      "Leaf size  30\n",
      "La moyenne est  0.7636\n",
      "Leaf size  50\n",
      "La moyenne est  0.7636\n",
      "Number of neighbors  5\n",
      "Leaf size  30\n",
      "La moyenne est  0.7752666666666668\n",
      "Leaf size  50\n",
      "La moyenne est  0.7752666666666668\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [3, 4, 5]\n",
    "leaf_size = [30, 50]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for leaf in leaf_size:\n",
    "        print(\"Leaf size \", leaf)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='uniform', leaf_size=leaf, p=1)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  5\n",
      "La moyenne est  0.7752666666666668\n",
      "Number of neighbors  6\n",
      "La moyenne est  0.7689333333333332\n",
      "Number of neighbors  7\n",
      "La moyenne est  0.7693333333333333\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [5, 6, 7]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n, p=1)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  5\n",
      "Leaf size  30\n",
      "La moyenne est  0.7752666666666668\n",
      "Leaf size  90\n",
      "La moyenne est  0.7752666666666668\n",
      "Leaf size  120\n",
      "La moyenne est  0.7752666666666668\n",
      "Number of neighbors  6\n",
      "Leaf size  30\n",
      "La moyenne est  0.7689333333333332\n",
      "Leaf size  90\n",
      "La moyenne est  0.7689333333333332\n",
      "Leaf size  120\n",
      "La moyenne est  0.7689333333333332\n",
      "Number of neighbors  7\n",
      "Leaf size  30\n",
      "La moyenne est  0.7693333333333333\n",
      "Leaf size  90\n",
      "La moyenne est  0.7693333333333333\n",
      "Leaf size  120\n",
      "La moyenne est  0.7693333333333333\n",
      "Number of neighbors  8\n",
      "Leaf size  30\n",
      "La moyenne est  0.7696\n",
      "Leaf size  90\n",
      "La moyenne est  0.7696\n",
      "Leaf size  120\n",
      "La moyenne est  0.7696\n",
      "Number of neighbors  9\n",
      "Leaf size  30\n",
      "La moyenne est  0.7725333333333333\n",
      "Leaf size  90\n",
      "La moyenne est  0.7725333333333333\n",
      "Leaf size  120\n",
      "La moyenne est  0.7725333333333333\n",
      "Number of neighbors  10\n",
      "Leaf size  30\n",
      "La moyenne est  0.7700000000000001\n",
      "Leaf size  90\n",
      "La moyenne est  0.7700000000000001\n",
      "Leaf size  120\n",
      "La moyenne est  0.7700000000000001\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [5,6,7,8,9,10]\n",
    "leaf_size = [30, 90, 120]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for leaf in leaf_size:\n",
    "        print(\"Leaf size \", leaf)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='uniform', leaf_size=leaf, p=1)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  5\n",
      "Power  1\n",
      "La moyenne est  0.7752666666666668\n",
      "Power  2\n",
      "La moyenne est  0.7097333333333333\n",
      "Number of neighbors  10\n",
      "Power  1\n",
      "La moyenne est  0.7700000000000001\n",
      "Power  2\n",
      "La moyenne est  0.6994\n",
      "Number of neighbors  15\n",
      "Power  1\n",
      "La moyenne est  0.7683333333333333\n",
      "Power  2\n",
      "La moyenne est  0.7009333333333334\n",
      "Number of neighbors  20\n",
      "Power  1\n",
      "La moyenne est  0.7664666666666666\n",
      "Power  2\n",
      "La moyenne est  0.6909333333333334\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [5,10,15,20]\n",
    "power = [1,2]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for p in power:\n",
    "        print(\"Power \", p)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='uniform', p=p)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  5\n",
      "Power  1\n",
      "La moyenne est  0.7699333333333334\n",
      "Power  2\n",
      "La moyenne est  0.7029333333333333\n",
      "Number of neighbors  10\n",
      "Power  1\n",
      "La moyenne est  0.7721333333333333\n",
      "Power  2\n",
      "La moyenne est  0.7022666666666667\n",
      "Number of neighbors  15\n",
      "Power  1\n",
      "La moyenne est  0.7691333333333333\n",
      "Power  2\n",
      "La moyenne est  0.7001999999999999\n",
      "Number of neighbors  20\n",
      "Power  1\n",
      "La moyenne est  0.7676666666666667\n",
      "Power  2\n",
      "La moyenne est  0.6939333333333333\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [5,10,15,20]\n",
    "power = [1,2]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for p in power:\n",
    "        print(\"Power \", p)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='distance', p=p)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   1       2       3       4       5       6  \\\n",
      "Power 1 and uniform weights   0.7456  0.7438  0.7695  0.7636  0.7753  0.7689   \n",
      "Power 2 and uniform weights   0.6878  0.6869  0.7061     NaN  0.7097     NaN   \n",
      "Power 1 and distance weights  0.7456  0.7456  0.7635     NaN  0.7699     NaN   \n",
      "Power 2 and distance weights  0.6878  0.6878  0.6988     NaN  0.7029     NaN   \n",
      "\n",
      "                                   7       8       9      10      15      20  \n",
      "Power 1 and uniform weights   0.7693  0.7696  0.7725  0.7700  0.7683  0.7664  \n",
      "Power 2 and uniform weights      NaN     NaN     NaN  0.6994  0.7009  0.6909  \n",
      "Power 1 and distance weights     NaN     NaN     NaN  0.7721  0.7691  0.7676  \n",
      "Power 2 and distance weights     NaN     NaN     NaN  0.7023  0.7002  0.6939  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_table(column_names, row_names, matrix):\n",
    "    df = pd.DataFrame(matrix, columns=column_names, index=row_names)\n",
    "    return df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '15', '20']\n",
    "rows = ['Power 1 and uniform weights', 'Power 2 and uniform weights', 'Power 1 and distance weights', 'Power 2 and distance weights']\n",
    "data = [[0.7456, 0.7438, 0.7695, 0.7636, 0.7753, 0.7689, 0.7693, 0.7696, 0.7725, 0.7700, 0.7683, 0.7664],\n",
    "        [0.6878, 0.6869, 0.7061, None, 0.7097, None, None, None, None, 0.6994, 0.7009, 0.6909],\n",
    "        [0.7456, 0.7456, 0.7635, None, 0.7699, None, None, None, None, 0.7721, 0.7691, 0.7676],\n",
    "        [0.6878, 0.6878, 0.6988, None, 0.7029, None, None, None, None, 0.7023, 0.7002, 0.6939]]\n",
    "\n",
    "tableau = create_table(columns, rows, data)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(tableau)\n",
    "\n",
    "# Création de l'image à partir du tableau\n",
    "plt.imshow(tableau.values, cmap='plasma', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(columns)), columns)\n",
    "plt.yticks(range(len(rows)), rows)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(p=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5,p=1,weights='uniform')\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 0.8526\n",
      "[[4074  709  217]\n",
      " [ 229 4421  350]\n",
      " [  61  645 4294]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 0.7796666666666666\n",
      "[[730 218  52]\n",
      " [ 69 835  96]\n",
      " [ 18 208 774]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Trees\n",
    "\n",
    "[Decision Trees](http://scikit-learn.org/stable/modules/tree.html#tree) classify the data by splitting the feature space according to simple, single-feature rules. Scikit-learn uses the [CART](https://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees_.28CART.29) algorithm for [its implementation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) of the classifier. \n",
    "\n",
    "* **Create a simple Decision Tree classifier** using scikit-learn and train it on the HoG training set.\n",
    "* Use cross-validation to find the best hyper-paramters for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 1.0\n",
      "[[5000    0    0]\n",
      " [   0 5000    0]\n",
      " [   0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.5696666666666667\n",
      "[[598 231 171]\n",
      " [208 531 261]\n",
      " [156 264 580]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = [\"random\", \"best\"]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_split = [0.5, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitter  random\n",
      "Criterion  gini\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.4886666666666667\n",
      "Min samples split  2\n",
      "La moyenne est  0.5566000000000001\n",
      "Min samples split  3\n",
      "La moyenne est  0.5565333333333333\n",
      "Min samples split  4\n",
      "La moyenne est  0.5501333333333334\n",
      "Criterion  entropy\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.4698666666666667\n",
      "Min samples split  2\n",
      "La moyenne est  0.5572666666666666\n",
      "Min samples split  3\n",
      "La moyenne est  0.5610666666666666\n",
      "Min samples split  4\n",
      "La moyenne est  0.5574\n",
      "Splitter  best\n",
      "Criterion  gini\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.5302\n",
      "Min samples split  2\n",
      "La moyenne est  0.5754666666666666\n",
      "Min samples split  3\n",
      "La moyenne est  0.5788666666666668\n",
      "Min samples split  4\n",
      "La moyenne est  0.5763999999999999\n",
      "Criterion  entropy\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.5006\n",
      "Min samples split  2\n",
      "La moyenne est  0.5704666666666667\n",
      "Min samples split  3\n",
      "La moyenne est  0.5731333333333333\n",
      "Min samples split  4\n",
      "La moyenne est  0.5691333333333334\n"
     ]
    }
   ],
   "source": [
    "for s in splitter:\n",
    "    print(\"Splitter \", s)\n",
    "    for c in criterion:\n",
    "        print(\"Criterion \", c)\n",
    "        for m in min_samples_split:\n",
    "            print(\"Min samples split \", m)\n",
    "            clf = tree.DecisionTreeClassifier(splitter=s, criterion=c, min_samples_split=m)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=[\"sqrt\", \"log2\"]\n",
    "min_samples_split = [0.8, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max features  sqrt\n",
      "Criterion  gini\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.4468\n",
      "Min samples split  2\n",
      "La moyenne est  0.5424666666666667\n",
      "Min samples split  3\n",
      "La moyenne est  0.5406\n",
      "Min samples split  4\n",
      "La moyenne est  0.5468\n",
      "Min samples split  5\n",
      "La moyenne est  0.5486666666666667\n",
      "Criterion  entropy\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.4267333333333333\n",
      "Min samples split  2\n",
      "La moyenne est  0.5506\n",
      "Min samples split  3\n",
      "La moyenne est  0.5436666666666667\n",
      "Min samples split  4\n",
      "La moyenne est  0.5445333333333333\n",
      "Min samples split  5\n",
      "La moyenne est  0.5526\n",
      "Max features  log2\n",
      "Criterion  gini\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.43946666666666667\n",
      "Min samples split  2\n",
      "La moyenne est  0.5344\n",
      "Min samples split  3\n",
      "La moyenne est  0.5254\n",
      "Min samples split  4\n",
      "La moyenne est  0.5275333333333333\n",
      "Min samples split  5\n",
      "La moyenne est  0.5346666666666667\n",
      "Criterion  entropy\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.43406666666666666\n",
      "Min samples split  2\n",
      "La moyenne est  0.5360666666666666\n",
      "Min samples split  3\n",
      "La moyenne est  0.5358666666666667\n",
      "Min samples split  4\n",
      "La moyenne est  0.5324\n",
      "Min samples split  5\n",
      "La moyenne est  0.5346\n"
     ]
    }
   ],
   "source": [
    "for f in max_features:\n",
    "    print(\"Max features \", f)\n",
    "    for c in criterion:\n",
    "        print(\"Criterion \", c)\n",
    "        for m in min_samples_split:\n",
    "            print(\"Min samples split \", m)\n",
    "            clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=c, min_samples_split=m, max_features=f)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [2, 4, 5, 7, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max features  sqrt\n",
      "Criterion  gini\n",
      "Min samples split  10\n",
      "La moyenne est  0.5362\n",
      "Min samples split  15\n",
      "La moyenne est  0.5497333333333333\n",
      "Min samples split  20\n",
      "La moyenne est  0.5511999999999999\n",
      "Criterion  entropy\n",
      "Min samples split  10\n",
      "La moyenne est  0.5406666666666666\n",
      "Min samples split  15\n",
      "La moyenne est  0.5520666666666667\n",
      "Min samples split  20\n",
      "La moyenne est  0.5566000000000001\n",
      "Max features  log2\n",
      "Criterion  gini\n",
      "Min samples split  10\n",
      "La moyenne est  0.5391333333333334\n",
      "Min samples split  15\n",
      "La moyenne est  0.5461333333333334\n",
      "Min samples split  20\n",
      "La moyenne est  0.5456666666666667\n",
      "Criterion  entropy\n",
      "Min samples split  10\n",
      "La moyenne est  0.5384666666666666\n",
      "Min samples split  15\n",
      "La moyenne est  0.5443333333333333\n",
      "Min samples split  20\n",
      "La moyenne est  0.5510666666666666\n"
     ]
    }
   ],
   "source": [
    "for f in max_features:\n",
    "    print(\"Max features \", f)\n",
    "    for c in criterion:\n",
    "        print(\"Criterion \", c)\n",
    "        for m in min_samples_split:\n",
    "            print(\"Min samples split \", m)\n",
    "            clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=c, min_samples_split=m, max_features=f)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [45, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min samples split  45\n",
      "Criterion  gini\n",
      "La moyenne est  0.5843333333333333\n",
      "Criterion  entropy\n",
      "La moyenne est  0.5884\n",
      "Min samples split  50\n",
      "Criterion  gini\n",
      "La moyenne est  0.5864\n",
      "Criterion  entropy\n",
      "La moyenne est  0.5874666666666666\n",
      "Min samples split  60\n",
      "Criterion  gini\n",
      "La moyenne est  0.5874\n",
      "Criterion  entropy\n",
      "La moyenne est  0.5909333333333333\n"
     ]
    }
   ],
   "source": [
    "for m in min_samples_split:\n",
    "    print(\"Min samples split \", m)\n",
    "    for c in criterion:\n",
    "        print(\"Criterion \", c)\n",
    "        clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=c, min_samples_split=m)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0.5     0.8       2       3       4       5      10  \\\n",
      "Gini & sqrt        NaN  0.4468  0.5425  0.5406  0.5468  0.5487  0.5362   \n",
      "Gini & log2        NaN  0.4395  0.5344  0.5254  0.5275  0.5347  0.5391   \n",
      "Gini & None     0.5302     NaN  0.5755  0.5789  0.5764  0.5752  0.5790   \n",
      "Entropy & sqrt     NaN  0.4267  0.5506  0.5437  0.5445  0.5526  0.5407   \n",
      "Entropy & log2     NaN  0.4341  0.5361  0.5359  0.5324  0.5346  0.5385   \n",
      "Entropy & None  0.5006     NaN  0.5705  0.5731  0.5691     NaN  0.5721   \n",
      "\n",
      "                    15      20      25      30      35      40      45  \\\n",
      "Gini & sqrt     0.5497  0.5512     NaN     NaN     NaN     NaN     NaN   \n",
      "Gini & log2     0.5461  0.5457     NaN     NaN     NaN     NaN     NaN   \n",
      "Gini & None     0.5769  0.5779  0.5806  0.5804  0.5845  0.5843  0.5843   \n",
      "Entropy & sqrt  0.5521  0.5566     NaN     NaN     NaN     NaN     NaN   \n",
      "Entropy & log2  0.5443  0.5511     NaN     NaN     NaN     NaN     NaN   \n",
      "Entropy & None  0.5688  0.5733  0.5788  0.5796  0.5844  0.5873  0.5884   \n",
      "\n",
      "                    50      60  \n",
      "Gini & sqrt        NaN     NaN  \n",
      "Gini & log2        NaN     NaN  \n",
      "Gini & None     0.5864  0.5874  \n",
      "Entropy & sqrt     NaN     NaN  \n",
      "Entropy & log2     NaN     NaN  \n",
      "Entropy & None  0.5875  0.5909  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_table(column_names, row_names, matrix):\n",
    "    df = pd.DataFrame(matrix, columns=column_names, index=row_names)\n",
    "    return df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "columns = ['0.5', '0.8', '2', '3', '4', '5', '10', '15', '20', '25', '30', '35', '40', '45', '50', '60']\n",
    "rows = ['Gini & sqrt', 'Gini & log2', 'Gini & None', 'Entropy & sqrt', 'Entropy & log2', 'Entropy & None']\n",
    "data = [[None, 0.4468, 0.5425, 0.5406, 0.5468, 0.5487, 0.5362, 0.5497, 0.5512, None, None, None, None, None, None, None],\n",
    "        [None, 0.4395, 0.5344, 0.5254, 0.5275, 0.5347, 0.5391, 0.5461, 0.5457, None, None, None, None, None, None, None],\n",
    "        [0.5302, None, 0.5755, 0.5789, 0.5764, 0.5752, 0.579, 0.5769, 0.5779, 0.5806, 0.5804, 0.5845, 0.5843, 0.5843, 0.5864, 0.5874],\n",
    "        [None, 0.4267, 0.5506, 0.5437, 0.5445, 0.5526, 0.5407, 0.5521, 0.5566, None, None, None, None, None, None, None],\n",
    "        [None, 0.4341, 0.5361, 0.5359, 0.5324, 0.5346, 0.5385, 0.5443, 0.5511, None, None, None, None, None, None, None],\n",
    "        [0.5006, None, 0.5705, 0.5731, 0.5691, None, 0.5721, 0.5688, 0.5733, 0.5788, 0.5796, 0.5844, 0.5873, 0.5884, 0.5875, 0.5909]]\n",
    "\n",
    "tableau = create_table(columns, rows, data)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(tableau)\n",
    "\n",
    "# Création de l'image à partir du tableau\n",
    "plt.imshow(tableau.values, cmap='plasma', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(columns)), columns)\n",
    "plt.yticks(range(len(rows)), rows)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [90, 100, 120, 140, 160, 170, 180, 190, 200, 220, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion  gini\n",
      "Min samples split  90\n",
      "La moyenne est  0.5904\n",
      "Min samples split  100\n",
      "La moyenne est  0.5897333333333333\n",
      "Min samples split  120\n",
      "La moyenne est  0.5896666666666667\n",
      "Min samples split  140\n",
      "La moyenne est  0.5892666666666666\n",
      "Min samples split  160\n",
      "La moyenne est  0.5927333333333333\n",
      "Min samples split  170\n",
      "La moyenne est  0.5919333333333333\n",
      "Min samples split  180\n",
      "La moyenne est  0.5920666666666666\n",
      "Min samples split  190\n",
      "La moyenne est  0.5926\n",
      "Min samples split  200\n",
      "La moyenne est  0.5926\n",
      "Min samples split  220\n",
      "La moyenne est  0.5923333333333334\n",
      "Min samples split  300\n",
      "La moyenne est  0.587\n",
      "Criterion  entropy\n",
      "Min samples split  90\n",
      "La moyenne est  0.5921333333333333\n",
      "Min samples split  100\n",
      "La moyenne est  0.5942666666666667\n",
      "Min samples split  120\n",
      "La moyenne est  0.5948666666666667\n",
      "Min samples split  140\n",
      "La moyenne est  0.5945333333333334\n",
      "Min samples split  160\n",
      "La moyenne est  0.5944666666666667\n",
      "Min samples split  170\n",
      "La moyenne est  0.5944\n",
      "Min samples split  180\n",
      "La moyenne est  0.5949333333333333\n",
      "Min samples split  190\n",
      "La moyenne est  0.5939333333333334\n",
      "Min samples split  200\n",
      "La moyenne est  0.5942666666666667\n",
      "Min samples split  220\n",
      "La moyenne est  0.5944666666666667\n",
      "Min samples split  300\n",
      "La moyenne est  0.5919333333333332\n"
     ]
    }
   ],
   "source": [
    "final_list = []\n",
    "for c in criterion:\n",
    "    list_c = []\n",
    "    print(\"Criterion \", c)\n",
    "    for m in min_samples_split:\n",
    "        print(\"Min samples split \", m)\n",
    "        clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=c, min_samples_split=m)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        list_c.append(mean)\n",
    "        print(\"La moyenne est \", mean)\n",
    "    final_list.append(list_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      90       100       120       140       160       170  \\\n",
      "Gini & None     0.590400  0.589733  0.589667  0.589267  0.592733  0.591933   \n",
      "Entropy & None  0.592133  0.594267  0.594867  0.594533  0.594467  0.594400   \n",
      "\n",
      "                     180       190       200       220       300  \n",
      "Gini & None     0.592067  0.592600  0.592600  0.592333  0.587000  \n",
      "Entropy & None  0.594933  0.593933  0.594267  0.594467  0.591933  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_table(column_names, row_names, matrix):\n",
    "    df = pd.DataFrame(matrix, columns=column_names, index=row_names)\n",
    "    return df\n",
    "\n",
    "# Exemple d'utilisation\n",
    "columns = ['90', '100', '120', '140', '160', '170', '180', '190', '200', '220', '300']\n",
    "rows = ['Gini & None','Entropy & None']\n",
    "data = final_list\n",
    "\n",
    "tableau = create_table(columns, rows, data)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(tableau)\n",
    "\n",
    "# Création de l'image à partir du tableau\n",
    "plt.imshow(tableau.values, cmap='plasma', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(columns)), columns)\n",
    "plt.yticks(range(len(rows)), rows)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', min_samples_split=180)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=\"entropy\", min_samples_split=180)\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(155.63870689655172, 210.645, 'X[16] <= 0.002\\nentropy = 1.585\\nsamples = 15000\\nvalue = [5000, 5000, 5000]'),\n",
       " Text(83.98862068965516, 197.055, 'X[168] <= 0.011\\nentropy = 1.479\\nsamples = 6495\\nvalue = [3369, 1650, 1476]'),\n",
       " Text(43.87034482758621, 183.465, 'X[224] <= 0.002\\nentropy = 1.572\\nsamples = 4280\\nvalue = [1688, 1348, 1244]'),\n",
       " Text(23.666896551724136, 169.875, 'X[190] <= 0.004\\nentropy = 1.363\\nsamples = 1420\\nvalue = [859, 270, 291]'),\n",
       " Text(15.008275862068965, 156.285, 'X[36] <= 0.002\\nentropy = 1.212\\nsamples = 1063\\nvalue = [719, 222, 122]'),\n",
       " Text(9.235862068965517, 142.695, 'X[111] <= 0.001\\nentropy = 1.005\\nsamples = 758\\nvalue = [577, 126, 55]'),\n",
       " Text(4.617931034482758, 129.10500000000002, 'X[181] <= 0.001\\nentropy = 0.603\\nsamples = 317\\nvalue = [281, 27, 9]'),\n",
       " Text(2.308965517241379, 115.515, 'entropy = 0.884\\nsamples = 121\\nvalue = [95, 22, 4]'),\n",
       " Text(6.926896551724138, 115.515, 'X[27] <= 0.001\\nentropy = 0.342\\nsamples = 196\\nvalue = [186, 5, 5]'),\n",
       " Text(4.617931034482758, 101.925, 'entropy = 0.104\\nsamples = 147\\nvalue = [145, 2, 0]'),\n",
       " Text(9.235862068965517, 101.925, 'entropy = 0.798\\nsamples = 49\\nvalue = [41, 3, 5]'),\n",
       " Text(13.853793103448275, 129.10500000000002, 'X[103] <= 0.002\\nentropy = 1.21\\nsamples = 441\\nvalue = [296, 99, 46]'),\n",
       " Text(11.544827586206896, 115.515, 'entropy = 1.306\\nsamples = 94\\nvalue = [41, 46, 7]'),\n",
       " Text(16.162758620689655, 115.515, 'X[225] <= 0.001\\nentropy = 1.095\\nsamples = 347\\nvalue = [255, 53, 39]'),\n",
       " Text(13.853793103448275, 101.925, 'X[5] <= 0.003\\nentropy = 0.863\\nsamples = 254\\nvalue = [208, 25, 21]'),\n",
       " Text(11.544827586206896, 88.33500000000001, 'X[94] <= 0.005\\nentropy = 0.664\\nsamples = 208\\nvalue = [181, 20, 7]'),\n",
       " Text(9.235862068965517, 74.745, 'entropy = 0.427\\nsamples = 149\\nvalue = [136, 13, 0]'),\n",
       " Text(13.853793103448275, 74.745, 'entropy = 1.028\\nsamples = 59\\nvalue = [45, 7, 7]'),\n",
       " Text(16.162758620689655, 88.33500000000001, 'entropy = 1.322\\nsamples = 46\\nvalue = [27, 5, 14]'),\n",
       " Text(18.471724137931034, 101.925, 'entropy = 1.478\\nsamples = 93\\nvalue = [47, 28, 18]'),\n",
       " Text(20.780689655172413, 142.695, 'X[66] <= 0.002\\nentropy = 1.519\\nsamples = 305\\nvalue = [142, 96, 67]'),\n",
       " Text(18.471724137931034, 129.10500000000002, 'entropy = 1.262\\nsamples = 166\\nvalue = [92, 63, 11]'),\n",
       " Text(23.089655172413792, 129.10500000000002, 'entropy = 1.552\\nsamples = 139\\nvalue = [50, 33, 56]'),\n",
       " Text(32.32551724137931, 156.285, 'X[144] <= 0.005\\nentropy = 1.43\\nsamples = 357\\nvalue = [140, 48, 169]'),\n",
       " Text(30.01655172413793, 142.695, 'X[180] <= 0.006\\nentropy = 1.479\\nsamples = 210\\nvalue = [108, 44, 58]'),\n",
       " Text(27.70758620689655, 129.10500000000002, 'entropy = 1.545\\nsamples = 173\\nvalue = [74, 41, 58]'),\n",
       " Text(32.32551724137931, 129.10500000000002, 'entropy = 0.406\\nsamples = 37\\nvalue = [34, 3, 0]'),\n",
       " Text(34.63448275862069, 142.695, 'entropy = 0.926\\nsamples = 147\\nvalue = [32, 4, 111]'),\n",
       " Text(64.07379310344827, 169.875, 'X[66] <= 0.002\\nentropy = 1.577\\nsamples = 2860\\nvalue = [829, 1078, 953]'),\n",
       " Text(49.642758620689655, 156.285, 'X[71] <= 0.001\\nentropy = 1.524\\nsamples = 1621\\nvalue = [558, 719, 344]'),\n",
       " Text(41.561379310344826, 142.695, 'X[82] <= 0.003\\nentropy = 1.294\\nsamples = 665\\nvalue = [190, 405, 70]'),\n",
       " Text(36.94344827586207, 129.10500000000002, 'X[108] <= 0.009\\nentropy = 1.347\\nsamples = 320\\nvalue = [140, 151, 29]'),\n",
       " Text(34.63448275862069, 115.515, 'X[137] <= 0.005\\nentropy = 1.376\\nsamples = 247\\nvalue = [129, 90, 28]'),\n",
       " Text(32.32551724137931, 101.925, 'X[70] <= 0.001\\nentropy = 1.439\\nsamples = 197\\nvalue = [85, 85, 27]'),\n",
       " Text(30.01655172413793, 88.33500000000001, 'entropy = 1.25\\nsamples = 147\\nvalue = [72, 67, 8]'),\n",
       " Text(34.63448275862069, 88.33500000000001, 'entropy = 1.566\\nsamples = 50\\nvalue = [13, 18, 19]'),\n",
       " Text(36.94344827586207, 101.925, 'entropy = 0.607\\nsamples = 50\\nvalue = [44, 5, 1]'),\n",
       " Text(39.25241379310344, 115.515, 'entropy = 0.713\\nsamples = 73\\nvalue = [11, 61, 1]'),\n",
       " Text(46.179310344827584, 129.10500000000002, 'X[190] <= 0.009\\nentropy = 1.094\\nsamples = 345\\nvalue = [50, 254, 41]'),\n",
       " Text(43.87034482758621, 115.515, 'X[208] <= 0.007\\nentropy = 0.987\\nsamples = 305\\nvalue = [47, 235, 23]'),\n",
       " Text(41.561379310344826, 101.925, 'entropy = 1.329\\nsamples = 133\\nvalue = [34, 81, 18]'),\n",
       " Text(46.179310344827584, 101.925, 'entropy = 0.573\\nsamples = 172\\nvalue = [13, 154, 5]'),\n",
       " Text(48.48827586206896, 115.515, 'entropy = 1.309\\nsamples = 40\\nvalue = [3, 19, 18]'),\n",
       " Text(57.72413793103448, 142.695, 'X[182] <= 0.008\\nentropy = 1.574\\nsamples = 956\\nvalue = [368, 314, 274]'),\n",
       " Text(55.4151724137931, 129.10500000000002, 'X[74] <= 0.008\\nentropy = 1.584\\nsamples = 846\\nvalue = [282, 297, 267]'),\n",
       " Text(53.106206896551726, 115.515, 'X[2] <= 0.002\\nentropy = 1.577\\nsamples = 746\\nvalue = [214, 277, 255]'),\n",
       " Text(50.79724137931034, 101.925, 'X[128] <= 0.011\\nentropy = 1.566\\nsamples = 616\\nvalue = [196, 250, 170]'),\n",
       " Text(48.48827586206896, 88.33500000000001, 'X[116] <= 0.005\\nentropy = 1.545\\nsamples = 574\\nvalue = [190, 247, 137]'),\n",
       " Text(46.179310344827584, 74.745, 'X[224] <= 0.009\\nentropy = 1.527\\nsamples = 446\\nvalue = [116, 210, 120]'),\n",
       " Text(43.87034482758621, 61.155, 'X[39] <= 0.004\\nentropy = 1.581\\nsamples = 277\\nvalue = [90, 102, 85]'),\n",
       " Text(41.561379310344826, 47.565, 'entropy = 1.485\\nsamples = 114\\nvalue = [55, 38, 21]'),\n",
       " Text(46.179310344827584, 47.565, 'entropy = 1.536\\nsamples = 163\\nvalue = [35, 64, 64]'),\n",
       " Text(48.48827586206896, 61.155, 'entropy = 1.299\\nsamples = 169\\nvalue = [26, 108, 35]'),\n",
       " Text(50.79724137931034, 74.745, 'entropy = 1.361\\nsamples = 128\\nvalue = [74, 37, 17]'),\n",
       " Text(53.106206896551726, 88.33500000000001, 'entropy = 0.946\\nsamples = 42\\nvalue = [6, 3, 33]'),\n",
       " Text(55.4151724137931, 101.925, 'entropy = 1.267\\nsamples = 130\\nvalue = [18, 27, 85]'),\n",
       " Text(57.72413793103448, 115.515, 'entropy = 1.21\\nsamples = 100\\nvalue = [68, 20, 12]'),\n",
       " Text(60.03310344827586, 129.10500000000002, 'entropy = 0.947\\nsamples = 110\\nvalue = [86, 17, 7]'),\n",
       " Text(78.50482758620689, 156.285, 'X[175] <= 0.004\\nentropy = 1.501\\nsamples = 1239\\nvalue = [271, 359, 609]'),\n",
       " Text(69.26896551724138, 142.695, 'X[72] <= 0.007\\nentropy = 1.572\\nsamples = 576\\nvalue = [160, 224, 192]'),\n",
       " Text(64.65103448275862, 129.10500000000002, 'X[22] <= 0.003\\nentropy = 1.454\\nsamples = 307\\nvalue = [69, 166, 72]'),\n",
       " Text(62.34206896551724, 115.515, 'entropy = 1.533\\nsamples = 150\\nvalue = [56, 62, 32]'),\n",
       " Text(66.96, 115.515, 'entropy = 1.194\\nsamples = 157\\nvalue = [13, 104, 40]'),\n",
       " Text(73.88689655172413, 129.10500000000002, 'X[21] <= 0.004\\nentropy = 1.526\\nsamples = 269\\nvalue = [91, 58, 120]'),\n",
       " Text(71.57793103448276, 115.515, 'X[46] <= 0.001\\nentropy = 1.443\\nsamples = 207\\nvalue = [85, 29, 93]'),\n",
       " Text(69.26896551724138, 101.925, 'entropy = 1.364\\nsamples = 139\\nvalue = [76, 16, 47]'),\n",
       " Text(73.88689655172413, 101.925, 'entropy = 1.224\\nsamples = 68\\nvalue = [9, 13, 46]'),\n",
       " Text(76.19586206896551, 115.515, 'entropy = 1.361\\nsamples = 62\\nvalue = [6, 29, 27]'),\n",
       " Text(87.74068965517242, 142.695, 'X[55] <= 0.002\\nentropy = 1.32\\nsamples = 663\\nvalue = [111, 135, 417]'),\n",
       " Text(83.12275862068965, 129.10500000000002, 'X[120] <= 0.005\\nentropy = 1.521\\nsamples = 310\\nvalue = [68, 99, 143]'),\n",
       " Text(80.81379310344828, 115.515, 'entropy = 1.451\\nsamples = 139\\nvalue = [28, 75, 36]'),\n",
       " Text(85.43172413793103, 115.515, 'entropy = 1.311\\nsamples = 171\\nvalue = [40, 24, 107]'),\n",
       " Text(92.35862068965517, 129.10500000000002, 'X[128] <= 0.011\\nentropy = 0.99\\nsamples = 353\\nvalue = [43, 36, 274]'),\n",
       " Text(90.0496551724138, 115.515, 'X[149] <= 0.013\\nentropy = 1.192\\nsamples = 252\\nvalue = [42, 35, 175]'),\n",
       " Text(87.74068965517242, 101.925, 'X[138] <= 0.008\\nentropy = 1.08\\nsamples = 233\\nvalue = [30, 30, 173]'),\n",
       " Text(85.43172413793103, 88.33500000000001, 'X[116] <= 0.004\\nentropy = 0.955\\nsamples = 216\\nvalue = [19, 27, 170]'),\n",
       " Text(83.12275862068965, 74.745, 'entropy = 0.785\\nsamples = 175\\nvalue = [6, 24, 145]'),\n",
       " Text(87.74068965517242, 74.745, 'entropy = 1.237\\nsamples = 41\\nvalue = [13, 3, 25]'),\n",
       " Text(90.0496551724138, 88.33500000000001, 'entropy = 1.29\\nsamples = 17\\nvalue = [11, 3, 3]'),\n",
       " Text(92.35862068965517, 101.925, 'entropy = 1.267\\nsamples = 19\\nvalue = [12, 5, 2]'),\n",
       " Text(94.66758620689654, 115.515, 'entropy = 0.16\\nsamples = 101\\nvalue = [1, 1, 99]'),\n",
       " Text(124.10689655172413, 183.465, 'X[152] <= 0.019\\nentropy = 1.035\\nsamples = 2215\\nvalue = [1681, 302, 232]'),\n",
       " Text(114.29379310344827, 169.875, 'X[208] <= 0.004\\nentropy = 1.27\\nsamples = 1389\\nvalue = [911, 263, 215]'),\n",
       " Text(108.52137931034483, 156.285, 'X[27] <= 0.003\\nentropy = 0.978\\nsamples = 848\\nvalue = [662, 92, 94]'),\n",
       " Text(106.21241379310345, 142.695, 'X[60] <= 0.003\\nentropy = 0.824\\nsamples = 748\\nvalue = [621, 74, 53]'),\n",
       " Text(103.90344827586206, 129.10500000000002, 'X[81] <= 0.006\\nentropy = 0.697\\nsamples = 686\\nvalue = [592, 66, 28]'),\n",
       " Text(101.59448275862069, 115.515, 'X[138] <= 0.003\\nentropy = 0.536\\nsamples = 581\\nvalue = [525, 42, 14]'),\n",
       " Text(96.97655172413792, 101.925, 'X[225] <= 0.001\\nentropy = 0.784\\nsamples = 273\\nvalue = [228, 33, 12]'),\n",
       " Text(94.66758620689654, 88.33500000000001, 'X[88] <= 0.002\\nentropy = 0.544\\nsamples = 203\\nvalue = [183, 15, 5]'),\n",
       " Text(92.35862068965517, 74.745, 'entropy = 1.105\\nsamples = 38\\nvalue = [26, 10, 2]'),\n",
       " Text(96.97655172413792, 74.745, 'entropy = 0.326\\nsamples = 165\\nvalue = [157, 5, 3]'),\n",
       " Text(99.28551724137931, 88.33500000000001, 'entropy = 1.246\\nsamples = 70\\nvalue = [45, 18, 7]'),\n",
       " Text(106.21241379310345, 101.925, 'X[18] <= 0.001\\nentropy = 0.247\\nsamples = 308\\nvalue = [297, 9, 2]'),\n",
       " Text(103.90344827586206, 88.33500000000001, 'X[237] <= 0.01\\nentropy = 0.064\\nsamples = 265\\nvalue = [263, 2, 0]'),\n",
       " Text(101.59448275862069, 74.745, 'entropy = 0.0\\nsamples = 261\\nvalue = [261, 0, 0]'),\n",
       " Text(106.21241379310345, 74.745, 'entropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(108.52137931034483, 88.33500000000001, 'entropy = 0.9\\nsamples = 43\\nvalue = [34, 7, 2]'),\n",
       " Text(106.21241379310345, 115.515, 'entropy = 1.288\\nsamples = 105\\nvalue = [67, 24, 14]'),\n",
       " Text(108.52137931034483, 129.10500000000002, 'entropy = 1.422\\nsamples = 62\\nvalue = [29, 8, 25]'),\n",
       " Text(110.8303448275862, 142.695, 'entropy = 1.5\\nsamples = 100\\nvalue = [41, 18, 41]'),\n",
       " Text(120.06620689655172, 156.285, 'X[183] <= 0.006\\nentropy = 1.524\\nsamples = 541\\nvalue = [249, 171, 121]'),\n",
       " Text(115.44827586206895, 142.695, 'X[171] <= 0.007\\nentropy = 1.568\\nsamples = 305\\nvalue = [91, 124, 90]'),\n",
       " Text(113.13931034482758, 129.10500000000002, 'X[191] <= 0.003\\nentropy = 1.558\\nsamples = 202\\nvalue = [59, 57, 86]'),\n",
       " Text(110.8303448275862, 115.515, 'entropy = 1.497\\nsamples = 102\\nvalue = [36, 47, 19]'),\n",
       " Text(115.44827586206895, 115.515, 'entropy = 1.207\\nsamples = 100\\nvalue = [23, 10, 67]'),\n",
       " Text(117.75724137931034, 129.10500000000002, 'entropy = 1.11\\nsamples = 103\\nvalue = [32, 67, 4]'),\n",
       " Text(124.68413793103448, 142.695, 'X[29] <= 0.002\\nentropy = 1.236\\nsamples = 236\\nvalue = [158, 47, 31]'),\n",
       " Text(122.3751724137931, 129.10500000000002, 'X[150] <= 0.003\\nentropy = 1.03\\nsamples = 199\\nvalue = [150, 33, 16]'),\n",
       " Text(120.06620689655172, 115.515, 'entropy = 1.534\\nsamples = 48\\nvalue = [22, 14, 12]'),\n",
       " Text(124.68413793103448, 115.515, 'entropy = 0.717\\nsamples = 151\\nvalue = [128, 19, 4]'),\n",
       " Text(126.99310344827586, 129.10500000000002, 'entropy = 1.536\\nsamples = 37\\nvalue = [8, 14, 15]'),\n",
       " Text(133.92, 169.875, 'X[182] <= 0.002\\nentropy = 0.418\\nsamples = 826\\nvalue = [770, 39, 17]'),\n",
       " Text(131.6110344827586, 156.285, 'entropy = 0.838\\nsamples = 167\\nvalue = [135, 26, 6]'),\n",
       " Text(136.22896551724136, 156.285, 'X[37] <= 0.002\\nentropy = 0.262\\nsamples = 659\\nvalue = [635, 13, 11]'),\n",
       " Text(133.92, 142.695, 'X[225] <= 0.001\\nentropy = 0.172\\nsamples = 583\\nvalue = [570, 10, 3]'),\n",
       " Text(131.6110344827586, 129.10500000000002, 'X[155] <= 0.0\\nentropy = 0.071\\nsamples = 466\\nvalue = [462, 4, 0]'),\n",
       " Text(129.30206896551724, 115.515, 'entropy = 0.433\\nsamples = 45\\nvalue = [41, 4, 0]'),\n",
       " Text(133.92, 115.515, 'entropy = 0.0\\nsamples = 421\\nvalue = [421, 0, 0]'),\n",
       " Text(136.22896551724136, 129.10500000000002, 'entropy = 0.462\\nsamples = 117\\nvalue = [108, 6, 3]'),\n",
       " Text(138.53793103448277, 142.695, 'entropy = 0.719\\nsamples = 76\\nvalue = [65, 3, 8]'),\n",
       " Text(227.28879310344826, 197.055, 'X[224] <= 0.003\\nentropy = 1.513\\nsamples = 8505\\nvalue = [1631, 3350, 3524]'),\n",
       " Text(171.15206896551723, 183.465, 'X[222] <= 0.001\\nentropy = 1.528\\nsamples = 3026\\nvalue = [922, 710, 1394]'),\n",
       " Text(157.58689655172412, 169.875, 'X[182] <= 0.007\\nentropy = 1.503\\nsamples = 1254\\nvalue = [589, 248, 417]'),\n",
       " Text(151.23724137931035, 156.285, 'X[152] <= 0.012\\nentropy = 1.532\\nsamples = 1051\\nvalue = [420, 222, 409]'),\n",
       " Text(145.4648275862069, 142.695, 'X[56] <= 0.003\\nentropy = 1.539\\nsamples = 818\\nvalue = [262, 194, 362]'),\n",
       " Text(140.84689655172414, 129.10500000000002, 'X[71] <= 0.004\\nentropy = 1.472\\nsamples = 237\\nvalue = [124, 62, 51]'),\n",
       " Text(138.53793103448277, 115.515, 'entropy = 1.464\\nsamples = 166\\nvalue = [80, 59, 27]'),\n",
       " Text(143.15586206896552, 115.515, 'entropy = 1.15\\nsamples = 71\\nvalue = [44, 3, 24]'),\n",
       " Text(150.08275862068965, 129.10500000000002, 'X[230] <= 0.001\\nentropy = 1.461\\nsamples = 581\\nvalue = [138, 132, 311]'),\n",
       " Text(147.77379310344827, 115.515, 'entropy = 1.46\\nsamples = 97\\nvalue = [52, 23, 22]'),\n",
       " Text(152.39172413793102, 115.515, 'X[144] <= 0.003\\nentropy = 1.371\\nsamples = 484\\nvalue = [86, 109, 289]'),\n",
       " Text(147.77379310344827, 101.925, 'X[32] <= 0.002\\nentropy = 1.558\\nsamples = 202\\nvalue = [57, 59, 86]'),\n",
       " Text(145.4648275862069, 88.33500000000001, 'entropy = 1.222\\nsamples = 44\\nvalue = [27, 3, 14]'),\n",
       " Text(150.08275862068965, 88.33500000000001, 'entropy = 1.502\\nsamples = 158\\nvalue = [30, 56, 72]'),\n",
       " Text(157.00965517241377, 101.925, 'X[192] <= 0.003\\nentropy = 1.121\\nsamples = 282\\nvalue = [29, 50, 203]'),\n",
       " Text(154.7006896551724, 88.33500000000001, 'X[72] <= 0.002\\nentropy = 0.895\\nsamples = 187\\nvalue = [21, 15, 151]'),\n",
       " Text(152.39172413793102, 74.745, 'entropy = 1.361\\nsamples = 10\\nvalue = [5, 4, 1]'),\n",
       " Text(157.00965517241377, 74.745, 'entropy = 0.765\\nsamples = 177\\nvalue = [16, 11, 150]'),\n",
       " Text(159.31862068965518, 88.33500000000001, 'entropy = 1.307\\nsamples = 95\\nvalue = [8, 35, 52]'),\n",
       " Text(157.00965517241377, 142.695, 'X[97] <= 0.001\\nentropy = 1.213\\nsamples = 233\\nvalue = [158, 28, 47]'),\n",
       " Text(154.7006896551724, 129.10500000000002, 'entropy = 0.709\\nsamples = 79\\nvalue = [66, 12, 1]'),\n",
       " Text(159.31862068965518, 129.10500000000002, 'entropy = 1.304\\nsamples = 154\\nvalue = [92, 16, 46]'),\n",
       " Text(163.93655172413793, 156.285, 'X[229] <= 0.004\\nentropy = 0.784\\nsamples = 203\\nvalue = [169, 26, 8]'),\n",
       " Text(161.62758620689655, 142.695, 'entropy = 0.603\\nsamples = 157\\nvalue = [140, 9, 8]'),\n",
       " Text(166.2455172413793, 142.695, 'entropy = 0.95\\nsamples = 46\\nvalue = [29, 17, 0]'),\n",
       " Text(184.71724137931034, 169.875, 'X[190] <= 0.004\\nentropy = 1.432\\nsamples = 1772\\nvalue = [333, 462, 977]'),\n",
       " Text(175.48137931034483, 156.285, 'X[175] <= 0.002\\nentropy = 1.547\\nsamples = 1065\\nvalue = [257, 353, 455]'),\n",
       " Text(170.86344827586205, 142.695, 'X[104] <= 0.018\\nentropy = 1.554\\nsamples = 394\\nvalue = [135, 162, 97]'),\n",
       " Text(168.55448275862068, 129.10500000000002, 'X[45] <= 0.003\\nentropy = 1.547\\nsamples = 354\\nvalue = [102, 157, 95]'),\n",
       " Text(166.2455172413793, 115.515, 'X[150] <= 0.007\\nentropy = 1.515\\nsamples = 252\\nvalue = [91, 111, 50]'),\n",
       " Text(163.93655172413793, 101.925, 'entropy = 1.528\\nsamples = 160\\nvalue = [41, 75, 44]'),\n",
       " Text(168.55448275862068, 101.925, 'entropy = 1.265\\nsamples = 92\\nvalue = [50, 36, 6]'),\n",
       " Text(170.86344827586205, 115.515, 'entropy = 1.385\\nsamples = 102\\nvalue = [11, 46, 45]'),\n",
       " Text(173.17241379310343, 129.10500000000002, 'entropy = 0.82\\nsamples = 40\\nvalue = [33, 5, 2]'),\n",
       " Text(180.0993103448276, 142.695, 'X[155] <= 0.012\\nentropy = 1.447\\nsamples = 671\\nvalue = [122, 191, 358]'),\n",
       " Text(177.7903448275862, 129.10500000000002, 'X[164] <= 0.012\\nentropy = 1.385\\nsamples = 595\\nvalue = [98, 151, 346]'),\n",
       " Text(175.48137931034483, 115.515, 'X[170] <= 0.01\\nentropy = 1.323\\nsamples = 545\\nvalue = [82, 124, 339]'),\n",
       " Text(173.17241379310343, 101.925, 'X[66] <= 0.004\\nentropy = 1.245\\nsamples = 501\\nvalue = [60, 111, 330]'),\n",
       " Text(170.86344827586205, 88.33500000000001, 'X[119] <= 0.005\\nentropy = 1.394\\nsamples = 327\\nvalue = [50, 92, 185]'),\n",
       " Text(168.55448275862068, 74.745, 'X[230] <= 0.001\\nentropy = 1.488\\nsamples = 197\\nvalue = [34, 76, 87]'),\n",
       " Text(166.2455172413793, 61.155, 'entropy = 1.509\\nsamples = 39\\nvalue = [19, 9, 11]'),\n",
       " Text(170.86344827586205, 61.155, 'entropy = 1.355\\nsamples = 158\\nvalue = [15, 67, 76]'),\n",
       " Text(173.17241379310343, 74.745, 'entropy = 1.051\\nsamples = 130\\nvalue = [16, 16, 98]'),\n",
       " Text(175.48137931034483, 88.33500000000001, 'entropy = 0.805\\nsamples = 174\\nvalue = [10, 19, 145]'),\n",
       " Text(177.7903448275862, 101.925, 'entropy = 1.488\\nsamples = 44\\nvalue = [22, 13, 9]'),\n",
       " Text(180.0993103448276, 115.515, 'entropy = 1.403\\nsamples = 50\\nvalue = [16, 27, 7]'),\n",
       " Text(182.40827586206896, 129.10500000000002, 'entropy = 1.433\\nsamples = 76\\nvalue = [24, 40, 12]'),\n",
       " Text(193.95310344827584, 156.285, 'X[170] <= 0.012\\nentropy = 1.085\\nsamples = 707\\nvalue = [76, 109, 522]'),\n",
       " Text(191.64413793103446, 142.695, 'X[159] <= 0.005\\nentropy = 0.972\\nsamples = 658\\nvalue = [52, 94, 512]'),\n",
       " Text(187.0262068965517, 129.10500000000002, 'X[107] <= 0.006\\nentropy = 1.302\\nsamples = 262\\nvalue = [34, 64, 164]'),\n",
       " Text(184.71724137931034, 115.515, 'entropy = 1.177\\nsamples = 173\\nvalue = [30, 22, 121]'),\n",
       " Text(189.3351724137931, 115.515, 'entropy = 1.219\\nsamples = 89\\nvalue = [4, 42, 43]'),\n",
       " Text(196.26206896551724, 129.10500000000002, 'X[9] <= 0.0\\nentropy = 0.649\\nsamples = 396\\nvalue = [18, 30, 348]'),\n",
       " Text(193.95310344827584, 115.515, 'entropy = 1.39\\nsamples = 58\\nvalue = [11, 13, 34]'),\n",
       " Text(198.57103448275862, 115.515, 'X[191] <= 0.009\\nentropy = 0.432\\nsamples = 338\\nvalue = [7, 17, 314]'),\n",
       " Text(196.26206896551724, 101.925, 'entropy = 0.706\\nsamples = 165\\nvalue = [7, 16, 142]'),\n",
       " Text(200.88, 101.925, 'entropy = 0.051\\nsamples = 173\\nvalue = [0, 1, 172]'),\n",
       " Text(196.26206896551724, 142.695, 'entropy = 1.495\\nsamples = 49\\nvalue = [24, 15, 10]'),\n",
       " Text(283.4255172413793, 183.465, 'X[128] <= 0.006\\nentropy = 1.419\\nsamples = 5479\\nvalue = [709, 2640, 2130]'),\n",
       " Text(250.52275862068964, 169.875, 'X[192] <= 0.003\\nentropy = 1.411\\nsamples = 4163\\nvalue = [587, 2211, 1365]'),\n",
       " Text(220.5062068965517, 156.285, 'X[144] <= 0.003\\nentropy = 1.502\\nsamples = 1715\\nvalue = [313, 679, 723]'),\n",
       " Text(212.4248275862069, 142.695, 'X[116] <= 0.011\\nentropy = 1.506\\nsamples = 775\\nvalue = [174, 378, 223]'),\n",
       " Text(210.1158620689655, 129.10500000000002, 'X[169] <= 0.007\\nentropy = 1.483\\nsamples = 737\\nvalue = [145, 369, 223]'),\n",
       " Text(207.80689655172412, 115.515, 'X[198] <= 0.0\\nentropy = 1.428\\nsamples = 561\\nvalue = [80, 284, 197]'),\n",
       " Text(205.49793103448275, 101.925, 'entropy = 1.361\\nsamples = 48\\nvalue = [25, 18, 5]'),\n",
       " Text(210.1158620689655, 101.925, 'X[71] <= 0.004\\nentropy = 1.367\\nsamples = 513\\nvalue = [55, 266, 192]'),\n",
       " Text(205.49793103448275, 88.33500000000001, 'X[67] <= 0.015\\nentropy = 1.243\\nsamples = 294\\nvalue = [27, 187, 80]'),\n",
       " Text(203.18896551724137, 74.745, 'X[18] <= 0.009\\nentropy = 1.218\\nsamples = 284\\nvalue = [27, 187, 70]'),\n",
       " Text(200.88, 61.155, 'X[186] <= 0.001\\nentropy = 1.167\\nsamples = 264\\nvalue = [26, 183, 55]'),\n",
       " Text(198.57103448275862, 47.565, 'entropy = 0.764\\nsamples = 119\\nvalue = [9, 101, 9]'),\n",
       " Text(203.18896551724137, 47.565, 'entropy = 1.353\\nsamples = 145\\nvalue = [17, 82, 46]'),\n",
       " Text(205.49793103448275, 61.155, 'entropy = 0.992\\nsamples = 20\\nvalue = [1, 4, 15]'),\n",
       " Text(207.80689655172412, 74.745, 'entropy = 0.0\\nsamples = 10\\nvalue = [0, 0, 10]'),\n",
       " Text(214.73379310344828, 88.33500000000001, 'X[139] <= 0.005\\nentropy = 1.405\\nsamples = 219\\nvalue = [28, 79, 112]'),\n",
       " Text(212.4248275862069, 74.745, 'X[66] <= 0.004\\nentropy = 1.331\\nsamples = 187\\nvalue = [21, 57, 109]'),\n",
       " Text(210.1158620689655, 61.155, 'entropy = 1.416\\nsamples = 134\\nvalue = [17, 53, 64]'),\n",
       " Text(214.73379310344828, 61.155, 'entropy = 0.763\\nsamples = 53\\nvalue = [4, 4, 45]'),\n",
       " Text(217.04275862068965, 74.745, 'entropy = 1.171\\nsamples = 32\\nvalue = [7, 22, 3]'),\n",
       " Text(212.4248275862069, 115.515, 'entropy = 1.445\\nsamples = 176\\nvalue = [65, 85, 26]'),\n",
       " Text(214.73379310344828, 129.10500000000002, 'entropy = 0.79\\nsamples = 38\\nvalue = [29, 9, 0]'),\n",
       " Text(228.58758620689653, 142.695, 'X[191] <= 0.006\\nentropy = 1.418\\nsamples = 940\\nvalue = [139, 301, 500]'),\n",
       " Text(223.96965517241378, 129.10500000000002, 'X[72] <= 0.003\\nentropy = 1.499\\nsamples = 691\\nvalue = [127, 255, 309]'),\n",
       " Text(221.6606896551724, 115.515, 'entropy = 1.439\\nsamples = 165\\nvalue = [40, 91, 34]'),\n",
       " Text(226.27862068965516, 115.515, 'X[0] <= 0.003\\nentropy = 1.443\\nsamples = 526\\nvalue = [87, 164, 275]'),\n",
       " Text(221.6606896551724, 101.925, 'X[247] <= 0.0\\nentropy = 1.564\\nsamples = 227\\nvalue = [66, 67, 94]'),\n",
       " Text(219.35172413793103, 88.33500000000001, 'entropy = 0.863\\nsamples = 21\\nvalue = [15, 6, 0]'),\n",
       " Text(223.96965517241378, 88.33500000000001, 'X[124] <= 0.001\\nentropy = 1.535\\nsamples = 206\\nvalue = [51, 61, 94]'),\n",
       " Text(221.6606896551724, 74.745, 'entropy = 1.545\\nsamples = 94\\nvalue = [26, 42, 26]'),\n",
       " Text(226.27862068965516, 74.745, 'entropy = 1.354\\nsamples = 112\\nvalue = [25, 19, 68]'),\n",
       " Text(230.8965517241379, 101.925, 'X[240] <= 0.003\\nentropy = 1.234\\nsamples = 299\\nvalue = [21, 97, 181]'),\n",
       " Text(228.58758620689653, 88.33500000000001, 'entropy = 1.213\\nsamples = 148\\nvalue = [17, 31, 100]'),\n",
       " Text(233.2055172413793, 88.33500000000001, 'entropy = 1.143\\nsamples = 151\\nvalue = [4, 66, 81]'),\n",
       " Text(233.2055172413793, 129.10500000000002, 'X[158] <= 0.008\\nentropy = 0.954\\nsamples = 249\\nvalue = [12, 46, 191]'),\n",
       " Text(230.8965517241379, 115.515, 'entropy = 1.292\\nsamples = 121\\nvalue = [11, 39, 71]'),\n",
       " Text(235.5144827586207, 115.515, 'entropy = 0.371\\nsamples = 128\\nvalue = [1, 7, 120]'),\n",
       " Text(280.5393103448276, 156.285, 'X[156] <= 0.012\\nentropy = 1.283\\nsamples = 2448\\nvalue = [274, 1532, 642]'),\n",
       " Text(267.84, 142.695, 'X[72] <= 0.012\\nentropy = 1.331\\nsamples = 2143\\nvalue = [256, 1269, 618]'),\n",
       " Text(253.98620689655172, 129.10500000000002, 'X[174] <= 0.004\\nentropy = 1.272\\nsamples = 1814\\nvalue = [197, 1145, 472]'),\n",
       " Text(244.7503448275862, 115.515, 'X[150] <= 0.011\\nentropy = 1.22\\nsamples = 1048\\nvalue = [134, 710, 204]'),\n",
       " Text(242.44137931034481, 101.925, 'X[55] <= 0.002\\nentropy = 1.196\\nsamples = 932\\nvalue = [98, 634, 200]'),\n",
       " Text(237.82344827586206, 88.33500000000001, 'X[103] <= 0.013\\nentropy = 1.028\\nsamples = 526\\nvalue = [51, 400, 75]'),\n",
       " Text(235.5144827586207, 74.745, 'X[23] <= 0.001\\nentropy = 0.959\\nsamples = 495\\nvalue = [37, 387, 71]'),\n",
       " Text(233.2055172413793, 61.155, 'entropy = 0.612\\nsamples = 153\\nvalue = [14, 135, 4]'),\n",
       " Text(237.82344827586206, 61.155, 'X[169] <= 0.01\\nentropy = 1.047\\nsamples = 342\\nvalue = [23, 252, 67]'),\n",
       " Text(235.5144827586207, 47.565, 'X[190] <= 0.006\\nentropy = 1.017\\nsamples = 302\\nvalue = [14, 221, 67]'),\n",
       " Text(233.2055172413793, 33.974999999999994, 'X[244] <= 0.0\\nentropy = 0.95\\nsamples = 257\\nvalue = [14, 199, 44]'),\n",
       " Text(230.8965517241379, 20.38499999999999, 'entropy = 1.441\\nsamples = 42\\nvalue = [6, 20, 16]'),\n",
       " Text(235.5144827586207, 20.38499999999999, 'X[98] <= 0.001\\nentropy = 0.78\\nsamples = 215\\nvalue = [8, 179, 28]'),\n",
       " Text(233.2055172413793, 6.7949999999999875, 'entropy = 1.28\\nsamples = 62\\nvalue = [7, 39, 16]'),\n",
       " Text(237.82344827586206, 6.7949999999999875, 'entropy = 0.453\\nsamples = 153\\nvalue = [1, 140, 12]'),\n",
       " Text(237.82344827586206, 33.974999999999994, 'entropy = 1.0\\nsamples = 45\\nvalue = [0, 22, 23]'),\n",
       " Text(240.13241379310344, 47.565, 'entropy = 0.769\\nsamples = 40\\nvalue = [9, 31, 0]'),\n",
       " Text(240.13241379310344, 74.745, 'entropy = 1.425\\nsamples = 31\\nvalue = [14, 13, 4]'),\n",
       " Text(247.05931034482757, 88.33500000000001, 'X[129] <= 0.003\\nentropy = 1.342\\nsamples = 406\\nvalue = [47, 234, 125]'),\n",
       " Text(244.7503448275862, 74.745, 'X[29] <= 0.0\\nentropy = 1.291\\nsamples = 276\\nvalue = [40, 177, 59]'),\n",
       " Text(242.44137931034481, 61.155, 'entropy = 0.996\\nsamples = 28\\nvalue = [15, 13, 0]'),\n",
       " Text(247.05931034482757, 61.155, 'X[116] <= 0.0\\nentropy = 1.221\\nsamples = 248\\nvalue = [25, 164, 59]'),\n",
       " Text(244.7503448275862, 47.565, 'entropy = 0.977\\nsamples = 34\\nvalue = [0, 14, 20]'),\n",
       " Text(249.36827586206897, 47.565, 'X[51] <= 0.009\\nentropy = 1.169\\nsamples = 214\\nvalue = [25, 150, 39]'),\n",
       " Text(247.05931034482757, 33.974999999999994, 'X[163] <= 0.002\\nentropy = 1.088\\nsamples = 202\\nvalue = [17, 147, 38]'),\n",
       " Text(244.7503448275862, 20.38499999999999, 'entropy = 1.154\\nsamples = 74\\nvalue = [3, 45, 26]'),\n",
       " Text(249.36827586206897, 20.38499999999999, 'entropy = 0.93\\nsamples = 128\\nvalue = [14, 102, 12]'),\n",
       " Text(251.67724137931035, 33.974999999999994, 'entropy = 1.189\\nsamples = 12\\nvalue = [8, 3, 1]'),\n",
       " Text(249.36827586206897, 74.745, 'entropy = 1.245\\nsamples = 130\\nvalue = [7, 57, 66]'),\n",
       " Text(247.05931034482757, 101.925, 'entropy = 1.091\\nsamples = 116\\nvalue = [36, 76, 4]'),\n",
       " Text(263.2220689655172, 115.515, 'X[240] <= 0.004\\nentropy = 1.29\\nsamples = 766\\nvalue = [63, 435, 268]'),\n",
       " Text(258.6041379310345, 101.925, 'X[24] <= 0.006\\nentropy = 1.405\\nsamples = 295\\nvalue = [35, 124, 136]'),\n",
       " Text(256.29517241379307, 88.33500000000001, 'X[212] <= 0.001\\nentropy = 1.434\\nsamples = 215\\nvalue = [30, 104, 81]'),\n",
       " Text(253.98620689655172, 74.745, 'entropy = 1.351\\nsamples = 38\\nvalue = [9, 6, 23]'),\n",
       " Text(258.6041379310345, 74.745, 'entropy = 1.365\\nsamples = 177\\nvalue = [21, 98, 58]'),\n",
       " Text(260.9131034482759, 88.33500000000001, 'entropy = 1.122\\nsamples = 80\\nvalue = [5, 20, 55]'),\n",
       " Text(267.84, 101.925, 'X[48] <= 0.0\\nentropy = 1.152\\nsamples = 471\\nvalue = [28, 311, 132]'),\n",
       " Text(265.5310344827586, 88.33500000000001, 'entropy = 1.131\\nsamples = 25\\nvalue = [4, 3, 18]'),\n",
       " Text(270.1489655172414, 88.33500000000001, 'X[5] <= 0.005\\nentropy = 1.099\\nsamples = 446\\nvalue = [24, 308, 114]'),\n",
       " Text(267.84, 74.745, 'X[66] <= 0.007\\nentropy = 1.06\\nsamples = 383\\nvalue = [24, 278, 81]'),\n",
       " Text(265.5310344827586, 61.155, 'X[115] <= 0.009\\nentropy = 0.983\\nsamples = 347\\nvalue = [21, 265, 61]'),\n",
       " Text(263.2220689655172, 47.565, 'X[92] <= 0.003\\nentropy = 0.948\\nsamples = 320\\nvalue = [14, 245, 61]'),\n",
       " Text(260.9131034482759, 33.974999999999994, 'entropy = 1.12\\nsamples = 160\\nvalue = [14, 114, 32]'),\n",
       " Text(265.5310344827586, 33.974999999999994, 'entropy = 0.683\\nsamples = 160\\nvalue = [0, 131, 29]'),\n",
       " Text(267.84, 47.565, 'entropy = 0.826\\nsamples = 27\\nvalue = [7, 20, 0]'),\n",
       " Text(270.1489655172414, 61.155, 'entropy = 1.301\\nsamples = 36\\nvalue = [3, 13, 20]'),\n",
       " Text(272.4579310344827, 74.745, 'entropy = 0.998\\nsamples = 63\\nvalue = [0, 30, 33]'),\n",
       " Text(281.6937931034483, 129.10500000000002, 'X[89] <= 0.015\\nentropy = 1.495\\nsamples = 329\\nvalue = [59, 124, 146]'),\n",
       " Text(279.3848275862069, 115.515, 'X[153] <= 0.008\\nentropy = 1.445\\nsamples = 313\\nvalue = [45, 122, 146]'),\n",
       " Text(277.07586206896553, 101.925, 'X[76] <= 0.003\\nentropy = 1.333\\nsamples = 249\\nvalue = [23, 94, 132]'),\n",
       " Text(274.76689655172413, 88.33500000000001, 'entropy = 1.238\\nsamples = 153\\nvalue = [15, 39, 99]'),\n",
       " Text(279.3848275862069, 88.33500000000001, 'entropy = 1.289\\nsamples = 96\\nvalue = [8, 55, 33]'),\n",
       " Text(281.6937931034483, 101.925, 'entropy = 1.531\\nsamples = 64\\nvalue = [22, 28, 14]'),\n",
       " Text(284.00275862068963, 115.515, 'entropy = 0.544\\nsamples = 16\\nvalue = [14, 2, 0]'),\n",
       " Text(293.23862068965514, 142.695, 'X[130] <= 0.007\\nentropy = 0.714\\nsamples = 305\\nvalue = [18, 263, 24]'),\n",
       " Text(290.9296551724138, 129.10500000000002, 'X[146] <= 0.002\\nentropy = 0.619\\nsamples = 275\\nvalue = [18, 244, 13]'),\n",
       " Text(288.6206896551724, 115.515, 'entropy = 0.189\\nsamples = 122\\nvalue = [2, 119, 1]'),\n",
       " Text(293.23862068965514, 115.515, 'entropy = 0.867\\nsamples = 153\\nvalue = [16, 125, 12]'),\n",
       " Text(295.54758620689654, 129.10500000000002, 'entropy = 0.948\\nsamples = 30\\nvalue = [0, 19, 11]'),\n",
       " Text(316.32827586206895, 169.875, 'X[208] <= 0.006\\nentropy = 1.3\\nsamples = 1316\\nvalue = [122, 429, 765]'),\n",
       " Text(307.09241379310345, 156.285, 'X[129] <= 0.004\\nentropy = 1.154\\nsamples = 628\\nvalue = [71, 113, 444]'),\n",
       " Text(302.4744827586207, 142.695, 'X[66] <= 0.005\\nentropy = 1.481\\nsamples = 208\\nvalue = [40, 64, 104]'),\n",
       " Text(300.1655172413793, 129.10500000000002, 'entropy = 1.566\\nsamples = 145\\nvalue = [40, 46, 59]'),\n",
       " Text(304.78344827586204, 129.10500000000002, 'entropy = 0.863\\nsamples = 63\\nvalue = [0, 18, 45]'),\n",
       " Text(311.7103448275862, 142.695, 'X[36] <= 0.002\\nentropy = 0.886\\nsamples = 420\\nvalue = [31, 49, 340]'),\n",
       " Text(309.4013793103448, 129.10500000000002, 'entropy = 1.242\\nsamples = 164\\nvalue = [25, 29, 110]'),\n",
       " Text(314.01931034482755, 129.10500000000002, 'X[118] <= 0.009\\nentropy = 0.553\\nsamples = 256\\nvalue = [6, 20, 230]'),\n",
       " Text(311.7103448275862, 115.515, 'X[81] <= 0.002\\nentropy = 0.435\\nsamples = 242\\nvalue = [1, 19, 222]'),\n",
       " Text(309.4013793103448, 101.925, 'entropy = 0.08\\nsamples = 101\\nvalue = [1, 0, 100]'),\n",
       " Text(314.01931034482755, 101.925, 'entropy = 0.57\\nsamples = 141\\nvalue = [0, 19, 122]'),\n",
       " Text(316.32827586206895, 115.515, 'entropy = 1.264\\nsamples = 14\\nvalue = [5, 1, 8]'),\n",
       " Text(325.56413793103445, 156.285, 'X[70] <= 0.002\\nentropy = 1.307\\nsamples = 688\\nvalue = [51, 316, 321]'),\n",
       " Text(320.9462068965517, 142.695, 'X[66] <= 0.0\\nentropy = 1.253\\nsamples = 382\\nvalue = [28, 226, 128]'),\n",
       " Text(318.63724137931035, 129.10500000000002, 'entropy = 1.567\\nsamples = 32\\nvalue = [13, 10, 9]'),\n",
       " Text(323.2551724137931, 129.10500000000002, 'X[56] <= 0.006\\nentropy = 1.154\\nsamples = 350\\nvalue = [15, 216, 119]'),\n",
       " Text(320.9462068965517, 115.515, 'X[19] <= 0.01\\nentropy = 1.119\\nsamples = 256\\nvalue = [15, 175, 66]'),\n",
       " Text(318.63724137931035, 101.925, 'X[192] <= 0.002\\nentropy = 1.179\\nsamples = 224\\nvalue = [14, 144, 66]'),\n",
       " Text(316.32827586206895, 88.33500000000001, 'entropy = 1.159\\nsamples = 15\\nvalue = [4, 1, 10]'),\n",
       " Text(320.9462068965517, 88.33500000000001, 'X[148] <= 0.006\\nentropy = 1.094\\nsamples = 209\\nvalue = [10, 143, 56]'),\n",
       " Text(318.63724137931035, 74.745, 'entropy = 1.095\\nsamples = 133\\nvalue = [3, 80, 50]'),\n",
       " Text(323.2551724137931, 74.745, 'entropy = 0.83\\nsamples = 76\\nvalue = [7, 63, 6]'),\n",
       " Text(323.2551724137931, 101.925, 'entropy = 0.201\\nsamples = 32\\nvalue = [1, 31, 0]'),\n",
       " Text(325.56413793103445, 115.515, 'entropy = 0.988\\nsamples = 94\\nvalue = [0, 41, 53]'),\n",
       " Text(330.1820689655172, 142.695, 'X[38] <= 0.002\\nentropy = 1.219\\nsamples = 306\\nvalue = [23, 90, 193]'),\n",
       " Text(327.87310344827586, 129.10500000000002, 'entropy = 1.436\\nsamples = 150\\nvalue = [22, 53, 75]'),\n",
       " Text(332.4910344827586, 129.10500000000002, 'entropy = 0.844\\nsamples = 156\\nvalue = [1, 37, 118]')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 0.6783333333333333\n",
      "[[3632  781  587]\n",
      " [ 857 2999 1144]\n",
      " [ 562  894 3544]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.5976666666666667\n",
      "[[663 206 131]\n",
      " [196 528 276]\n",
      " [168 230 602]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests\n",
    "\n",
    "[Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifiers use multiple decision trees trained on \"weaker\" datasets (less data and/or less features), averaging the results so as to reduce over-fitting.\n",
    "\n",
    "* Use scikit-learn to **create a Random Forest classifier** on the CIFAR data. \n",
    "* Use cross-validation to find the best hyper-paramters for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 1.0\n",
      "[[5000    0    0]\n",
      " [   0 5000    0]\n",
      " [   0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.772\n",
      "[[787 158  55]\n",
      " [121 745 134]\n",
      " [ 55 161 784]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 200]\n",
    "bootstrap = [True, False]\n",
    "class_weight = [\"balanced\", \"balanced_subsample\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  50\n",
      "Bootstrap\n",
      "La moyenne est  0.7462666666666666\n",
      "No bootstrap\n",
      "La moyenne est  0.7494666666666666\n",
      "Nb estimators  100\n",
      "Bootstrap\n",
      "La moyenne est  0.7558666666666667\n",
      "No bootstrap\n",
      "La moyenne est  0.7628666666666666\n",
      "Nb estimators  150\n",
      "Bootstrap\n",
      "La moyenne est  0.7661333333333333\n",
      "No bootstrap\n",
      "La moyenne est  0.7689333333333332\n",
      "Nb estimators  200\n",
      "Bootstrap\n",
      "La moyenne est  0.7668666666666667\n",
      "No bootstrap\n",
      "La moyenne est  0.7710666666666667\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    for b in bootstrap:\n",
    "        if b :\n",
    "            print(\"Bootstrap\")\n",
    "        else:\n",
    "            print(\"No bootstrap\")\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=b)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [250, 300, 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  250\n",
      "La moyenne est  0.7719333333333334\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7715333333333334\n",
      "Nb estimators  350\n",
      "La moyenne est  0.7734666666666666\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=False)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [350, 400, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  350\n",
      "La moyenne est  0.7761333333333333\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7734666666666666\n",
      "Nb estimators  450\n",
      "La moyenne est  0.7769333333333334\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=False)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [350, 400, 450, 500, 550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  350\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7738666666666666\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7742000000000001\n",
      "Class weight  None\n",
      "La moyenne est  0.7723333333333333\n",
      "Nb estimators  400\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7733333333333333\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7748666666666668\n",
      "Class weight  None\n",
      "La moyenne est  0.7734666666666667\n",
      "Nb estimators  450\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7756\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7748666666666667\n",
      "Class weight  None\n",
      "La moyenne est  0.7755333333333334\n",
      "Nb estimators  500\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7754\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7750666666666668\n",
      "Class weight  None\n",
      "La moyenne est  0.7754666666666666\n",
      "Nb estimators  550\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7771333333333332\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7746666666666666\n",
      "Class weight  None\n",
      "La moyenne est  0.7757333333333334\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    for w in class_weight:\n",
    "        print(\"Class weight \", w)\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=False, class_weight=w)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300, 400, 500, 600]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_split = [2, 10, 50, 100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion  gini\n",
      "Min sample  2\n",
      "Nb estimators  100\n",
      "La moyenne est  0.7632\n",
      "Nb estimators  200\n",
      "La moyenne est  0.7721333333333333\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7719333333333334\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7758\n",
      "Nb estimators  500\n",
      "La moyenne est  0.7737333333333334\n",
      "Nb estimators  600\n",
      "La moyenne est  0.7744\n",
      "Min sample  10\n",
      "Nb estimators  100\n",
      "La moyenne est  0.7646666666666666\n",
      "Nb estimators  200\n",
      "La moyenne est  0.7691333333333334\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7722\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7728666666666666\n",
      "Nb estimators  500\n",
      "La moyenne est  0.7746666666666666\n",
      "Nb estimators  600\n",
      "La moyenne est  0.7749333333333333\n",
      "Min sample  50\n",
      "Nb estimators  100\n",
      "La moyenne est  0.7573333333333334\n",
      "Nb estimators  200\n",
      "La moyenne est  0.7577333333333334\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7621333333333333\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7626\n",
      "Nb estimators  500\n",
      "La moyenne est  0.7646\n",
      "Nb estimators  600\n",
      "La moyenne est  0.7636666666666667\n",
      "Min sample  100\n",
      "Nb estimators  100\n",
      "La moyenne est  0.7502666666666667\n",
      "Nb estimators  200\n",
      "La moyenne est  0.7534000000000001\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7541333333333333\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7536666666666666\n",
      "Nb estimators  500\n",
      "La moyenne est  0.7534666666666667\n",
      "Nb estimators  600\n",
      "La moyenne est  0.7525999999999999\n",
      "Min sample  200\n",
      "Nb estimators  100\n",
      "La moyenne est  0.7379333333333333\n",
      "Nb estimators  200\n",
      "La moyenne est  0.7409333333333332\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7426666666666667\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7414\n",
      "Nb estimators  500\n",
      "La moyenne est  0.7418666666666666\n",
      "Nb estimators  600\n",
      "La moyenne est  0.7426666666666667\n",
      "Min sample  300\n",
      "Nb estimators  100\n",
      "La moyenne est  0.7313333333333334\n",
      "Nb estimators  200\n"
     ]
    }
   ],
   "source": [
    "final_list = []\n",
    "for c in criterion:\n",
    "    list_crit = []\n",
    "    print(\"Criterion \", c)\n",
    "    for min_s in min_samples_split:\n",
    "        print(\"Min sample \", min_s)\n",
    "        list_crit.append([])\n",
    "        for n in n_estimators:\n",
    "            print(\"Nb estimators \", n)\n",
    "            clf = ensemble.RandomForestClassifier(n_estimators=n, bootstrap=False, criterion=c, min_samples_split=min_s)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            list_crit[-1].append(mean)\n",
    "            print(\"La moyenne est \", mean)\n",
    "    final_list.append(list_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300, 400, 500, 600]\n",
    "criterion = [\"entropy\"]\n",
    "min_samples_split = [2, 10, 50, 100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion  entropy\n",
      "Min sample  2\n",
      "Nb estimators  100\n"
     ]
    }
   ],
   "source": [
    "final_list2 = []\n",
    "for c in criterion:\n",
    "    list_crit = []\n",
    "    print(\"Criterion \", c)\n",
    "    for min_s in min_samples_split:\n",
    "        print(\"Min sample \", min_s)\n",
    "        list_crit.append([])\n",
    "        for n in n_estimators:\n",
    "            print(\"Nb estimators \", n)\n",
    "            clf = ensemble.RandomForestClassifier(n_estimators=n, bootstrap=False, criterion=c, min_samples_split=min_s)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            list_crit[-1].append(mean)\n",
    "            print(\"La moyenne est \", mean)\n",
    "    final_list2.append(list_crit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
