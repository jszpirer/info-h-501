{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Nearest Neighbors and Decision Trees\n",
    "\n",
    "## Lab objectives\n",
    "\n",
    "* Classification with decision trees and random forests.\n",
    "* Cross-validation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading training data\n",
      "Pre-loading test data\n"
     ]
    }
   ],
   "source": [
    "from lab_tools import CIFAR10, get_hog_image\n",
    "\n",
    "dataset = CIFAR10('./CIFAR10/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Nearest Neighbor\n",
    "\n",
    "The following example uses the Nearest Neighbor algorithm on the Histogram of Gradient decriptors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the **descriptive performance** of this classifier ?\n",
    "* Modify the code to estimate the **predictive performance**.\n",
    "* Use cross-validation to find the best hyper-parameters for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 1.0\n",
      "[[5000    0    0]\n",
      " [   0 5000    0]\n",
      " [   0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.694\n",
      "[[609 258 133]\n",
      " [ 63 754 183]\n",
      " [ 26 255 719]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents hyperparameters sont les suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [1, 2, 3]\n",
    "weights = ['uniform', 'distance']\n",
    "p = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  1\n",
      "Weights  uniform\n",
      "Power  1\n",
      "La moyenne est  0.7456\n",
      "Power  2\n",
      "La moyenne est  0.6878\n",
      "Weights  distance\n",
      "Power  1\n",
      "La moyenne est  0.7456\n",
      "Power  2\n",
      "La moyenne est  0.6878\n",
      "Number of neighbors  2\n",
      "Weights  uniform\n",
      "Power  1\n",
      "La moyenne est  0.7438\n",
      "Power  2\n",
      "La moyenne est  0.6868666666666667\n",
      "Weights  distance\n",
      "Power  1\n",
      "La moyenne est  0.7456\n",
      "Power  2\n",
      "La moyenne est  0.6878\n",
      "Number of neighbors  3\n",
      "Weights  uniform\n",
      "Power  1\n",
      "La moyenne est  0.7695333333333333\n",
      "Power  2\n",
      "La moyenne est  0.7060666666666666\n",
      "Weights  distance\n",
      "Power  1\n",
      "La moyenne est  0.7635333333333333\n",
      "Power  2\n",
      "La moyenne est  0.6988\n"
     ]
    }
   ],
   "source": [
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for w in weights:\n",
    "        print(\"Weights \", w)\n",
    "        for power in p:\n",
    "            print(\"Power \", power)\n",
    "            clf = KNeighborsClassifier(n_neighbors=n, weights=w, p=power)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus le nombre de neighbors est grand, meilleure est l'accuracy. Power = 1 donne systématiquement des meilleurs résultats que power = 2.\n",
    "Pour neighbors = 3, weight = 'distance' était mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  3\n",
      "Weights  uniform\n",
      "Leaf size  20\n",
      "La moyenne est  0.7060666666666666\n",
      "Leaf size  30\n",
      "La moyenne est  0.7060666666666666\n",
      "Leaf size  40\n",
      "La moyenne est  0.7060666666666666\n",
      "Weights  distance\n",
      "Leaf size  20\n",
      "La moyenne est  0.6988\n",
      "Leaf size  30\n",
      "La moyenne est  0.6988\n",
      "Leaf size  40\n",
      "La moyenne est  0.6988\n",
      "Number of neighbors  4\n",
      "Weights  uniform\n",
      "Leaf size  20\n",
      "La moyenne est  0.7002\n",
      "Leaf size  30\n",
      "La moyenne est  0.7002\n",
      "Leaf size  40\n",
      "La moyenne est  0.7002\n",
      "Weights  distance\n",
      "Leaf size  20\n",
      "La moyenne est  0.7051999999999999\n",
      "Leaf size  30\n",
      "La moyenne est  0.7051999999999999\n",
      "Leaf size  40\n",
      "La moyenne est  0.7051999999999999\n",
      "Number of neighbors  5\n",
      "Weights  uniform\n",
      "Leaf size  20\n",
      "La moyenne est  0.7097333333333333\n",
      "Leaf size  30\n",
      "La moyenne est  0.7097333333333333\n",
      "Leaf size  40\n",
      "La moyenne est  0.7097333333333333\n",
      "Weights  distance\n",
      "Leaf size  20\n",
      "La moyenne est  0.7029333333333333\n",
      "Leaf size  30\n",
      "La moyenne est  0.7029333333333333\n",
      "Leaf size  40\n",
      "La moyenne est  0.7029333333333333\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [3, 4, 5]\n",
    "leaf_size = [20, 30, 40]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for w in weights:\n",
    "        print(\"Weights \", w)\n",
    "        for leaf in leaf_size:\n",
    "            print(\"Leaf size \", leaf)\n",
    "            clf = KNeighborsClassifier(n_neighbors=n, weights=w, leaf_size=leaf)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  3\n",
      "Leaf size  30\n",
      "La moyenne est  0.7695333333333333\n",
      "Leaf size  50\n",
      "La moyenne est  0.7695333333333333\n",
      "Number of neighbors  4\n",
      "Leaf size  30\n",
      "La moyenne est  0.7636\n",
      "Leaf size  50\n",
      "La moyenne est  0.7636\n",
      "Number of neighbors  5\n",
      "Leaf size  30\n",
      "La moyenne est  0.7752666666666668\n",
      "Leaf size  50\n",
      "La moyenne est  0.7752666666666668\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [3, 4, 5]\n",
    "leaf_size = [30, 50]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for leaf in leaf_size:\n",
    "        print(\"Leaf size \", leaf)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='uniform', leaf_size=leaf, p=1)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  5\n",
      "La moyenne est  0.7752666666666668\n",
      "Number of neighbors  6\n",
      "La moyenne est  0.7689333333333332\n",
      "Number of neighbors  7\n",
      "La moyenne est  0.7693333333333333\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [5, 6, 7]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n, p=1)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors  5\n",
      "Leaf size  30\n",
      "La moyenne est  0.7752666666666668\n",
      "Leaf size  90\n",
      "La moyenne est  0.7752666666666668\n",
      "Leaf size  120\n",
      "La moyenne est  0.7752666666666668\n",
      "Number of neighbors  6\n",
      "Leaf size  30\n",
      "La moyenne est  0.7689333333333332\n",
      "Leaf size  90\n",
      "La moyenne est  0.7689333333333332\n",
      "Leaf size  120\n",
      "La moyenne est  0.7689333333333332\n",
      "Number of neighbors  7\n",
      "Leaf size  30\n",
      "La moyenne est  0.7693333333333333\n",
      "Leaf size  90\n",
      "La moyenne est  0.7693333333333333\n",
      "Leaf size  120\n",
      "La moyenne est  0.7693333333333333\n",
      "Number of neighbors  8\n",
      "Leaf size  30\n",
      "La moyenne est  0.7696\n",
      "Leaf size  90\n",
      "La moyenne est  0.7696\n",
      "Leaf size  120\n",
      "La moyenne est  0.7696\n",
      "Number of neighbors  9\n",
      "Leaf size  30\n",
      "La moyenne est  0.7725333333333333\n",
      "Leaf size  90\n",
      "La moyenne est  0.7725333333333333\n",
      "Leaf size  120\n",
      "La moyenne est  0.7725333333333333\n",
      "Number of neighbors  10\n",
      "Leaf size  30\n",
      "La moyenne est  0.7700000000000001\n",
      "Leaf size  90\n",
      "La moyenne est  0.7700000000000001\n",
      "Leaf size  120\n",
      "La moyenne est  0.7700000000000001\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [5,6,7,8,9,10]\n",
    "leaf_size = [30, 90, 120]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for leaf in leaf_size:\n",
    "        print(\"Leaf size \", leaf)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='uniform', leaf_size=leaf, p=1)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [5,10,15,20]\n",
    "power = [1,2]\n",
    "for n in n_neighbors:\n",
    "    print(\"Number of neighbors \", n)\n",
    "    for p in power:\n",
    "        print(\"Power \", p)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n, weights='uniform', p=p)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Trees\n",
    "\n",
    "[Decision Trees](http://scikit-learn.org/stable/modules/tree.html#tree) classify the data by splitting the feature space according to simple, single-feature rules. Scikit-learn uses the [CART](https://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees_.28CART.29) algorithm for [its implementation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) of the classifier. \n",
    "\n",
    "* **Create a simple Decision Tree classifier** using scikit-learn and train it on the HoG training set.\n",
    "* Use cross-validation to find the best hyper-paramters for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 1.0\n",
      "[[5000    0    0]\n",
      " [   0 5000    0]\n",
      " [   0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.5696666666666667\n",
      "[[598 231 171]\n",
      " [208 531 261]\n",
      " [156 264 580]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = [\"random\", \"best\"]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_split = [0.5, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitter  random\n",
      "Criterion  gini\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.4886666666666667\n",
      "Min samples split  2\n",
      "La moyenne est  0.5566000000000001\n",
      "Min samples split  3\n",
      "La moyenne est  0.5565333333333333\n",
      "Min samples split  4\n",
      "La moyenne est  0.5501333333333334\n",
      "Criterion  entropy\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.4698666666666667\n",
      "Min samples split  2\n",
      "La moyenne est  0.5572666666666666\n",
      "Min samples split  3\n",
      "La moyenne est  0.5610666666666666\n",
      "Min samples split  4\n",
      "La moyenne est  0.5574\n",
      "Splitter  best\n",
      "Criterion  gini\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.5302\n",
      "Min samples split  2\n",
      "La moyenne est  0.5754666666666666\n",
      "Min samples split  3\n",
      "La moyenne est  0.5788666666666668\n",
      "Min samples split  4\n",
      "La moyenne est  0.5763999999999999\n",
      "Criterion  entropy\n",
      "Min samples split  0.5\n",
      "La moyenne est  0.5006\n",
      "Min samples split  2\n",
      "La moyenne est  0.5704666666666667\n",
      "Min samples split  3\n",
      "La moyenne est  0.5731333333333333\n",
      "Min samples split  4\n",
      "La moyenne est  0.5691333333333334\n"
     ]
    }
   ],
   "source": [
    "for s in splitter:\n",
    "    print(\"Splitter \", s)\n",
    "    for c in criterion:\n",
    "        print(\"Criterion \", c)\n",
    "        for m in min_samples_split:\n",
    "            print(\"Min samples split \", m)\n",
    "            clf = tree.DecisionTreeClassifier(splitter=s, criterion=c, min_samples_split=m)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=[\"sqrt\", \"log2\"]\n",
    "min_samples_split = [0.8, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max features  sqrt\n",
      "Criterion  gini\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.4468\n",
      "Min samples split  2\n",
      "La moyenne est  0.5424666666666667\n",
      "Min samples split  3\n",
      "La moyenne est  0.5406\n",
      "Min samples split  4\n",
      "La moyenne est  0.5468\n",
      "Min samples split  5\n",
      "La moyenne est  0.5486666666666667\n",
      "Criterion  entropy\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.4267333333333333\n",
      "Min samples split  2\n",
      "La moyenne est  0.5506\n",
      "Min samples split  3\n",
      "La moyenne est  0.5436666666666667\n",
      "Min samples split  4\n",
      "La moyenne est  0.5445333333333333\n",
      "Min samples split  5\n",
      "La moyenne est  0.5526\n",
      "Max features  log2\n",
      "Criterion  gini\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.43946666666666667\n",
      "Min samples split  2\n",
      "La moyenne est  0.5344\n",
      "Min samples split  3\n",
      "La moyenne est  0.5254\n",
      "Min samples split  4\n",
      "La moyenne est  0.5275333333333333\n",
      "Min samples split  5\n",
      "La moyenne est  0.5346666666666667\n",
      "Criterion  entropy\n",
      "Min samples split  0.8\n",
      "La moyenne est  0.43406666666666666\n",
      "Min samples split  2\n",
      "La moyenne est  0.5360666666666666\n",
      "Min samples split  3\n",
      "La moyenne est  0.5358666666666667\n",
      "Min samples split  4\n",
      "La moyenne est  0.5324\n",
      "Min samples split  5\n",
      "La moyenne est  0.5346\n"
     ]
    }
   ],
   "source": [
    "for f in max_features:\n",
    "    print(\"Max features \", f)\n",
    "    for c in criterion:\n",
    "        print(\"Criterion \", c)\n",
    "        for m in min_samples_split:\n",
    "            print(\"Min samples split \", m)\n",
    "            clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=c, min_samples_split=m, max_features=f)\n",
    "            scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "            mean = np.mean(scores)\n",
    "            print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [2, 4, 5, 7, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min samples split  2\n",
      "La moyenne est  0.5757333333333333\n",
      "Min samples split  4\n",
      "La moyenne est  0.5717333333333333\n",
      "Min samples split  5\n",
      "La moyenne est  0.5752666666666667\n",
      "Min samples split  7\n",
      "La moyenne est  0.5794666666666666\n",
      "Min samples split  9\n",
      "La moyenne est  0.5746666666666667\n",
      "Min samples split  10\n",
      "La moyenne est  0.5758666666666666\n"
     ]
    }
   ],
   "source": [
    "for m in min_samples_split:\n",
    "    print(\"Min samples split \", m)\n",
    "    clf = tree.DecisionTreeClassifier(splitter=\"best\", criterion=\"gini\", min_samples_split=m)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests\n",
    "\n",
    "[Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifiers use multiple decision trees trained on \"weaker\" datasets (less data and/or less features), averaging the results so as to reduce over-fitting.\n",
    "\n",
    "* Use scikit-learn to **create a Random Forest classifier** on the CIFAR data. \n",
    "* Use cross-validation to find the best hyper-paramters for this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit( dataset.train['hog'], dataset.train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive score 1.0\n",
      "[[5000    0    0]\n",
      " [   0 5000    0]\n",
      " [   0    0 5000]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.train['hog'])\n",
    "score = accuracy_score(dataset.train['labels'], pred)\n",
    "print(\"Descriptive score\", score)\n",
    "cm = confusion_matrix(dataset.train['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score 0.772\n",
      "[[787 158  55]\n",
      " [121 745 134]\n",
      " [ 55 161 784]]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(dataset.test['hog'])\n",
    "score = accuracy_score(dataset.test['labels'], pred)\n",
    "print(\"Predictive score\", score)\n",
    "cm = confusion_matrix(dataset.test['labels'], pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 200]\n",
    "bootstrap = [True, False]\n",
    "class_weight = [\"balanced\", \"balanced_subsample\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  50\n",
      "Bootstrap\n",
      "La moyenne est  0.7462666666666666\n",
      "No bootstrap\n",
      "La moyenne est  0.7494666666666666\n",
      "Nb estimators  100\n",
      "Bootstrap\n",
      "La moyenne est  0.7558666666666667\n",
      "No bootstrap\n",
      "La moyenne est  0.7628666666666666\n",
      "Nb estimators  150\n",
      "Bootstrap\n",
      "La moyenne est  0.7661333333333333\n",
      "No bootstrap\n",
      "La moyenne est  0.7689333333333332\n",
      "Nb estimators  200\n",
      "Bootstrap\n",
      "La moyenne est  0.7668666666666667\n",
      "No bootstrap\n",
      "La moyenne est  0.7710666666666667\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    for b in bootstrap:\n",
    "        if b :\n",
    "            print(\"Bootstrap\")\n",
    "        else:\n",
    "            print(\"No bootstrap\")\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=b)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [250, 300, 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  250\n",
      "La moyenne est  0.7719333333333334\n",
      "Nb estimators  300\n",
      "La moyenne est  0.7715333333333334\n",
      "Nb estimators  350\n",
      "La moyenne est  0.7734666666666666\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=False)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [350, 400, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  350\n",
      "La moyenne est  0.7761333333333333\n",
      "Nb estimators  400\n",
      "La moyenne est  0.7734666666666666\n",
      "Nb estimators  450\n",
      "La moyenne est  0.7769333333333334\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=False)\n",
    "    scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "    mean = np.mean(scores)\n",
    "    print(\"La moyenne est \", mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [350, 400, 450, 500, 550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb estimators  350\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7738666666666666\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7742000000000001\n",
      "Class weight  None\n",
      "La moyenne est  0.7723333333333333\n",
      "Nb estimators  400\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7733333333333333\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7748666666666668\n",
      "Class weight  None\n",
      "La moyenne est  0.7734666666666667\n",
      "Nb estimators  450\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7756\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7748666666666667\n",
      "Class weight  None\n",
      "La moyenne est  0.7755333333333334\n",
      "Nb estimators  500\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7754\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7750666666666668\n",
      "Class weight  None\n",
      "La moyenne est  0.7754666666666666\n",
      "Nb estimators  550\n",
      "Class weight  balanced\n",
      "La moyenne est  0.7771333333333332\n",
      "Class weight  balanced_subsample\n",
      "La moyenne est  0.7746666666666666\n",
      "Class weight  None\n",
      "La moyenne est  0.7757333333333334\n"
     ]
    }
   ],
   "source": [
    "for e in n_estimators:\n",
    "    print(\"Nb estimators \", e)\n",
    "    for w in class_weight:\n",
    "        print(\"Class weight \", w)\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=e, bootstrap=False, class_weight=w)\n",
    "        scores = cross_val_score(clf,dataset.train['hog'],dataset.train['labels'])\n",
    "        mean = np.mean(scores)\n",
    "        print(\"La moyenne est \", mean)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
